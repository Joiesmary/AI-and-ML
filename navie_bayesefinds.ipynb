{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8f0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "fruits = pd.read_table('fruit_data_with_colors.txt')\n",
    "feature_names = ['mass','width','height','color_score']   #all attributes\n",
    "\n",
    "x = fruits[feature_names]\n",
    "y = fruits['fruit_label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train1 = sc.fit_transform(x_train)\n",
    "x_test1= sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dd760da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15523583  0.36914738 -0.26388567  1.09384798]\n",
      " [-0.41650706  0.61524563  0.03193521 -0.09616246]\n",
      " [-0.04326244  0.36914738 -0.41179611  1.22607136]\n",
      " [-0.45383152  0.24609825 -0.48575133  1.49051812]\n",
      " [-0.19256029 -0.12304913 -0.48575133  1.6227415 ]\n",
      " [-0.60312937 -1.59963864  0.69753219 -0.36060922]\n",
      " [ 0.21800879  0.36914738 -0.41179611 -2.07951319]\n",
      " [ 0.4046311   0.12304913  1.06730829 -0.4928326 ]\n",
      " [ 3.31593912  2.33793339  1.21521873 -0.09616246]\n",
      " [-0.82707614 -1.35354039  0.47566653 -0.22838584]\n",
      " [-1.49891645 -1.35354039 -2.33463184  0.43273107]\n",
      " [ 0.1060354   0.61524563  0.10589043  1.6227415 ]\n",
      " [-1.46159199 -1.10744213 -2.26067662  0.56495445]\n",
      " [-0.00593798  0.24609825 -0.04202001 -0.75727937]\n",
      " [ 0.29265771  0.61524563  0.32775609  0.43273107]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7249a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn=MinMaxScaler()\n",
    "x_train2 = mn.fit_transform(x_train)\n",
    "x_test2 = mn.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "468c8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27972028 0.42105263 0.52307692 0.76315789]\n",
      " [0.23076923 0.47368421 0.58461538 0.52631579]\n",
      " [0.3006993  0.42105263 0.49230769 0.78947368]\n",
      " [0.22377622 0.39473684 0.47692308 0.84210526]\n",
      " [0.27272727 0.31578947 0.47692308 0.86842105]\n",
      " [0.1958042  0.         0.72307692 0.47368421]\n",
      " [0.34965035 0.42105263 0.49230769 0.13157895]\n",
      " [0.38461538 0.36842105 0.8        0.44736842]\n",
      " [0.93006993 0.84210526 0.83076923 0.52631579]\n",
      " [0.15384615 0.05263158 0.67692308 0.5       ]\n",
      " [0.02797203 0.05263158 0.09230769 0.63157895]\n",
      " [0.32867133 0.47368421 0.6        0.86842105]\n",
      " [0.03496503 0.10526316 0.10769231 0.65789474]\n",
      " [0.30769231 0.39473684 0.56923077 0.39473684]\n",
      " [0.36363636 0.47368421 0.64615385 0.63157895]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a311803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.29884753e-01 -7.38294756e-01  5.49621751e-01 -4.92832605e-01]\n",
      " [-9.01725066e-01 -1.35354039e+00 -1.89930452e-01 -4.92832605e-01]\n",
      " [ 3.57721035e+00  2.58403165e+00  1.06730829e+00 -9.61624595e-02]\n",
      " [ 5.16604483e-01  1.59963864e+00 -3.37840893e-01 -2.74063009e+00]\n",
      " [-1.92560292e-01  1.23049126e-01 -4.11796113e-01  8.29401213e-01]\n",
      " [-3.79182600e-01 -3.69147378e-01 -2.63885672e-01 -9.61624595e-02]\n",
      " [-2.29884753e-01  6.15245630e-01 -3.37840893e-01 -8.89502750e-01]\n",
      " [ 1.43359865e-01  3.69147378e-01 -5.59706554e-01  1.75496489e+00]\n",
      " [ 3.13864792e-02 -2.46098252e-01 -3.37840893e-01  2.28385841e+00]\n",
      " [-8.64400604e-01 -1.23049126e+00  2.53800870e-01 -7.57279368e-01]\n",
      " [-8.05869061e-02  4.92196504e-01 -1.89930452e-01  1.35829474e+00]\n",
      " [ 6.65902330e-01  2.46098252e-01  2.02872616e+00 -4.92832605e-01]\n",
      " [-1.57356538e+00 -1.59963864e+00 -2.55649750e+00  1.68284304e-01]\n",
      " [-8.05869061e-02 -1.23049126e-01 -2.63885672e-01  6.97177831e-01]\n",
      " [-1.92560292e-01 -1.09289578e-15 -1.89930452e-01  3.00507686e-01]\n",
      " [-9.01725066e-01 -1.23049126e+00  5.49621751e-01 -6.25055987e-01]\n",
      " [-1.64821430e+00 -1.59963864e+00 -2.77836316e+00  6.97177831e-01]\n",
      " [-1.17911368e-01 -1.09289578e-15 -1.89930452e-01  4.32731068e-01]\n",
      " [-8.64400604e-01 -1.47658951e+00  1.79845649e-01 -4.92832605e-01]\n",
      " [ 5.91253406e-01  2.46098252e-01  1.43708439e+00 -4.92832605e-01]\n",
      " [ 9.64498024e-01  2.46098252e-01  1.80686050e+00 -6.25055987e-01]\n",
      " [-1.57356538e+00 -1.47658951e+00 -2.55649750e+00  6.97177831e-01]\n",
      " [ 4.79280021e-01  4.92196504e-01  2.53800870e-01 -2.28385841e-01]\n",
      " [-6.40453833e-01 -1.35354039e+00  3.27756090e-01 -6.25055987e-01]\n",
      " [-9.01725066e-01 -9.84393008e-01 -4.20200115e-02 -4.92832605e-01]\n",
      " [-1.92560292e-01  2.46098252e-01 -3.37840893e-01  4.32731068e-01]\n",
      " [-9.01725066e-01 -1.47658951e+00  2.53800870e-01 -3.60609223e-01]\n",
      " [ 1.80684326e-01  2.46098252e-01  1.73290528e+00 -4.92832605e-01]\n",
      " [-4.53831524e-01 -4.92196504e-01 -4.85751333e-01 -4.92832605e-01]\n",
      " [ 8.52524639e-01  8.61343882e-01  1.79845649e-01  8.29401213e-01]\n",
      " [-1.55235830e-01  6.15245630e-01 -1.89930452e-01 -1.15394951e+00]\n",
      " [ 1.43359865e-01 -1.09289578e-15 -1.15975232e-01  2.15163503e+00]\n",
      " [-4.32624443e-02  4.92196504e-01 -4.85751333e-01  9.61624595e-01]\n",
      " [-5.93798256e-03  1.23049126e-01 -5.59706554e-01  5.64954449e-01]\n",
      " [ 2.55333250e-01 -1.09289578e-15  3.19352088e-02  2.15163503e+00]\n",
      " [ 2.92657712e-01  1.10744213e+00 -7.07616994e-01 -2.21173657e+00]\n",
      " [ 5.53928944e-01  1.23049126e-01  1.88081572e+00 -7.57279368e-01]\n",
      " [ 7.40551253e-01  4.92196504e-01  1.06730829e+00  1.68284304e-01]\n",
      " [-2.67209215e-01 -1.09289578e-15  1.05890429e-01 -9.61624595e-02]\n",
      " [-1.17911368e-01  1.23049126e-01  3.19352088e-02  1.68284304e-01]\n",
      " [ 3.68918373e+00  3.07622815e+00  1.06730829e+00 -2.28385841e-01]\n",
      " [-1.55235830e-01  7.38294756e-01 -4.85751333e-01 -8.89502750e-01]\n",
      " [ 6.87109410e-02  4.92196504e-01 -1.15975232e-01 -3.60609223e-01]\n",
      " [-8.05869061e-02 -1.09289578e-15 -1.15975232e-01  3.60609223e-02]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "564dd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26573427 0.18421053 0.69230769 0.44736842]\n",
      " [0.13986014 0.05263158 0.53846154 0.44736842]\n",
      " [0.97902098 0.89473684 0.8        0.52631579]\n",
      " [0.40559441 0.68421053 0.50769231 0.        ]\n",
      " [0.27272727 0.36842105 0.49230769 0.71052632]\n",
      " [0.23776224 0.26315789 0.52307692 0.52631579]\n",
      " [0.26573427 0.47368421 0.50769231 0.36842105]\n",
      " [0.33566434 0.42105263 0.46153846 0.89473684]\n",
      " [0.31468531 0.28947368 0.50769231 1.        ]\n",
      " [0.14685315 0.07894737 0.63076923 0.39473684]\n",
      " [0.29370629 0.44736842 0.53846154 0.81578947]\n",
      " [0.43356643 0.39473684 1.         0.44736842]\n",
      " [0.01398601 0.         0.04615385 0.57894737]\n",
      " [0.29370629 0.31578947 0.52307692 0.68421053]\n",
      " [0.27272727 0.34210526 0.53846154 0.60526316]\n",
      " [0.13986014 0.07894737 0.69230769 0.42105263]\n",
      " [0.         0.         0.         0.68421053]\n",
      " [0.28671329 0.34210526 0.53846154 0.63157895]\n",
      " [0.14685315 0.02631579 0.61538462 0.44736842]\n",
      " [0.41958042 0.39473684 0.87692308 0.44736842]\n",
      " [0.48951049 0.39473684 0.95384615 0.42105263]\n",
      " [0.01398601 0.02631579 0.04615385 0.68421053]\n",
      " [0.3986014  0.44736842 0.63076923 0.5       ]\n",
      " [0.18881119 0.05263158 0.64615385 0.42105263]\n",
      " [0.13986014 0.13157895 0.56923077 0.44736842]\n",
      " [0.27272727 0.39473684 0.50769231 0.63157895]\n",
      " [0.13986014 0.02631579 0.63076923 0.47368421]\n",
      " [0.34265734 0.39473684 0.93846154 0.44736842]\n",
      " [0.22377622 0.23684211 0.47692308 0.44736842]\n",
      " [0.46853147 0.52631579 0.61538462 0.71052632]\n",
      " [0.27972028 0.47368421 0.53846154 0.31578947]\n",
      " [0.33566434 0.34210526 0.55384615 0.97368421]\n",
      " [0.3006993  0.44736842 0.47692308 0.73684211]\n",
      " [0.30769231 0.36842105 0.46153846 0.65789474]\n",
      " [0.35664336 0.34210526 0.58461538 0.97368421]\n",
      " [0.36363636 0.57894737 0.43076923 0.10526316]\n",
      " [0.41258741 0.36842105 0.96923077 0.39473684]\n",
      " [0.44755245 0.44736842 0.8        0.57894737]\n",
      " [0.25874126 0.34210526 0.6        0.52631579]\n",
      " [0.28671329 0.36842105 0.58461538 0.57894737]\n",
      " [1.         1.         0.8        0.5       ]\n",
      " [0.27972028 0.5        0.47692308 0.36842105]\n",
      " [0.32167832 0.44736842 0.55384615 0.47368421]\n",
      " [0.29370629 0.34210526 0.55384615 0.55263158]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e839a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=pd.concat([pd.DataFrame(x_train1),pd.DataFrame(x_train2)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a981179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.229885</td>\n",
       "      <td>-7.382948e-01</td>\n",
       "      <td>0.549622</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.901725</td>\n",
       "      <td>-1.353540e+00</td>\n",
       "      <td>-0.189930</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.577210</td>\n",
       "      <td>2.584032e+00</td>\n",
       "      <td>1.067308</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.516604</td>\n",
       "      <td>1.599639e+00</td>\n",
       "      <td>-0.337841</td>\n",
       "      <td>-2.740630</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.192560</td>\n",
       "      <td>1.230491e-01</td>\n",
       "      <td>-0.411796</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.379183</td>\n",
       "      <td>-3.691474e-01</td>\n",
       "      <td>-0.263886</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>0.237762</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.229885</td>\n",
       "      <td>6.152456e-01</td>\n",
       "      <td>-0.337841</td>\n",
       "      <td>-0.889503</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.143360</td>\n",
       "      <td>3.691474e-01</td>\n",
       "      <td>-0.559707</td>\n",
       "      <td>1.754965</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031386</td>\n",
       "      <td>-2.460983e-01</td>\n",
       "      <td>-0.337841</td>\n",
       "      <td>2.283858</td>\n",
       "      <td>0.314685</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.864401</td>\n",
       "      <td>-1.230491e+00</td>\n",
       "      <td>0.253801</td>\n",
       "      <td>-0.757279</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.080587</td>\n",
       "      <td>4.921965e-01</td>\n",
       "      <td>-0.189930</td>\n",
       "      <td>1.358295</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.665902</td>\n",
       "      <td>2.460983e-01</td>\n",
       "      <td>2.028726</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.573565</td>\n",
       "      <td>-1.599639e+00</td>\n",
       "      <td>-2.556498</td>\n",
       "      <td>0.168284</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.080587</td>\n",
       "      <td>-1.230491e-01</td>\n",
       "      <td>-0.263886</td>\n",
       "      <td>0.697178</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.192560</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>-0.189930</td>\n",
       "      <td>0.300508</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.901725</td>\n",
       "      <td>-1.230491e+00</td>\n",
       "      <td>0.549622</td>\n",
       "      <td>-0.625056</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.648214</td>\n",
       "      <td>-1.599639e+00</td>\n",
       "      <td>-2.778363</td>\n",
       "      <td>0.697178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.117911</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>-0.189930</td>\n",
       "      <td>0.432731</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.864401</td>\n",
       "      <td>-1.476590e+00</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.591253</td>\n",
       "      <td>2.460983e-01</td>\n",
       "      <td>1.437084</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.964498</td>\n",
       "      <td>2.460983e-01</td>\n",
       "      <td>1.806860</td>\n",
       "      <td>-0.625056</td>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.573565</td>\n",
       "      <td>-1.476590e+00</td>\n",
       "      <td>-2.556498</td>\n",
       "      <td>0.697178</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.479280</td>\n",
       "      <td>4.921965e-01</td>\n",
       "      <td>0.253801</td>\n",
       "      <td>-0.228386</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.640454</td>\n",
       "      <td>-1.353540e+00</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>-0.625056</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.901725</td>\n",
       "      <td>-9.843930e-01</td>\n",
       "      <td>-0.042020</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.192560</td>\n",
       "      <td>2.460983e-01</td>\n",
       "      <td>-0.337841</td>\n",
       "      <td>0.432731</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.901725</td>\n",
       "      <td>-1.476590e+00</td>\n",
       "      <td>0.253801</td>\n",
       "      <td>-0.360609</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.180684</td>\n",
       "      <td>2.460983e-01</td>\n",
       "      <td>1.732905</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.453832</td>\n",
       "      <td>-4.921965e-01</td>\n",
       "      <td>-0.485751</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.223776</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.852525</td>\n",
       "      <td>8.613439e-01</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.468531</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.155236</td>\n",
       "      <td>6.152456e-01</td>\n",
       "      <td>-0.189930</td>\n",
       "      <td>-1.153950</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.143360</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>-0.115975</td>\n",
       "      <td>2.151635</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.043262</td>\n",
       "      <td>4.921965e-01</td>\n",
       "      <td>-0.485751</td>\n",
       "      <td>0.961625</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.005938</td>\n",
       "      <td>1.230491e-01</td>\n",
       "      <td>-0.559707</td>\n",
       "      <td>0.564954</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.255333</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>2.151635</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.292658</td>\n",
       "      <td>1.107442e+00</td>\n",
       "      <td>-0.707617</td>\n",
       "      <td>-2.211737</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.553929</td>\n",
       "      <td>1.230491e-01</td>\n",
       "      <td>1.880816</td>\n",
       "      <td>-0.757279</td>\n",
       "      <td>0.412587</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.740551</td>\n",
       "      <td>4.921965e-01</td>\n",
       "      <td>1.067308</td>\n",
       "      <td>0.168284</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.267209</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>0.258741</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.117911</td>\n",
       "      <td>1.230491e-01</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.168284</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.689184</td>\n",
       "      <td>3.076228e+00</td>\n",
       "      <td>1.067308</td>\n",
       "      <td>-0.228386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.155236</td>\n",
       "      <td>7.382948e-01</td>\n",
       "      <td>-0.485751</td>\n",
       "      <td>-0.889503</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.068711</td>\n",
       "      <td>4.921965e-01</td>\n",
       "      <td>-0.115975</td>\n",
       "      <td>-0.360609</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.080587</td>\n",
       "      <td>-1.092896e-15</td>\n",
       "      <td>-0.115975</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1         2         3         0         1         2  \\\n",
       "0  -0.229885 -7.382948e-01  0.549622 -0.492833  0.265734  0.184211  0.692308   \n",
       "1  -0.901725 -1.353540e+00 -0.189930 -0.492833  0.139860  0.052632  0.538462   \n",
       "2   3.577210  2.584032e+00  1.067308 -0.096162  0.979021  0.894737  0.800000   \n",
       "3   0.516604  1.599639e+00 -0.337841 -2.740630  0.405594  0.684211  0.507692   \n",
       "4  -0.192560  1.230491e-01 -0.411796  0.829401  0.272727  0.368421  0.492308   \n",
       "5  -0.379183 -3.691474e-01 -0.263886 -0.096162  0.237762  0.263158  0.523077   \n",
       "6  -0.229885  6.152456e-01 -0.337841 -0.889503  0.265734  0.473684  0.507692   \n",
       "7   0.143360  3.691474e-01 -0.559707  1.754965  0.335664  0.421053  0.461538   \n",
       "8   0.031386 -2.460983e-01 -0.337841  2.283858  0.314685  0.289474  0.507692   \n",
       "9  -0.864401 -1.230491e+00  0.253801 -0.757279  0.146853  0.078947  0.630769   \n",
       "10 -0.080587  4.921965e-01 -0.189930  1.358295  0.293706  0.447368  0.538462   \n",
       "11  0.665902  2.460983e-01  2.028726 -0.492833  0.433566  0.394737  1.000000   \n",
       "12 -1.573565 -1.599639e+00 -2.556498  0.168284  0.013986  0.000000  0.046154   \n",
       "13 -0.080587 -1.230491e-01 -0.263886  0.697178  0.293706  0.315789  0.523077   \n",
       "14 -0.192560 -1.092896e-15 -0.189930  0.300508  0.272727  0.342105  0.538462   \n",
       "15 -0.901725 -1.230491e+00  0.549622 -0.625056  0.139860  0.078947  0.692308   \n",
       "16 -1.648214 -1.599639e+00 -2.778363  0.697178  0.000000  0.000000  0.000000   \n",
       "17 -0.117911 -1.092896e-15 -0.189930  0.432731  0.286713  0.342105  0.538462   \n",
       "18 -0.864401 -1.476590e+00  0.179846 -0.492833  0.146853  0.026316  0.615385   \n",
       "19  0.591253  2.460983e-01  1.437084 -0.492833  0.419580  0.394737  0.876923   \n",
       "20  0.964498  2.460983e-01  1.806860 -0.625056  0.489510  0.394737  0.953846   \n",
       "21 -1.573565 -1.476590e+00 -2.556498  0.697178  0.013986  0.026316  0.046154   \n",
       "22  0.479280  4.921965e-01  0.253801 -0.228386  0.398601  0.447368  0.630769   \n",
       "23 -0.640454 -1.353540e+00  0.327756 -0.625056  0.188811  0.052632  0.646154   \n",
       "24 -0.901725 -9.843930e-01 -0.042020 -0.492833  0.139860  0.131579  0.569231   \n",
       "25 -0.192560  2.460983e-01 -0.337841  0.432731  0.272727  0.394737  0.507692   \n",
       "26 -0.901725 -1.476590e+00  0.253801 -0.360609  0.139860  0.026316  0.630769   \n",
       "27  0.180684  2.460983e-01  1.732905 -0.492833  0.342657  0.394737  0.938462   \n",
       "28 -0.453832 -4.921965e-01 -0.485751 -0.492833  0.223776  0.236842  0.476923   \n",
       "29  0.852525  8.613439e-01  0.179846  0.829401  0.468531  0.526316  0.615385   \n",
       "30 -0.155236  6.152456e-01 -0.189930 -1.153950  0.279720  0.473684  0.538462   \n",
       "31  0.143360 -1.092896e-15 -0.115975  2.151635  0.335664  0.342105  0.553846   \n",
       "32 -0.043262  4.921965e-01 -0.485751  0.961625  0.300699  0.447368  0.476923   \n",
       "33 -0.005938  1.230491e-01 -0.559707  0.564954  0.307692  0.368421  0.461538   \n",
       "34  0.255333 -1.092896e-15  0.031935  2.151635  0.356643  0.342105  0.584615   \n",
       "35  0.292658  1.107442e+00 -0.707617 -2.211737  0.363636  0.578947  0.430769   \n",
       "36  0.553929  1.230491e-01  1.880816 -0.757279  0.412587  0.368421  0.969231   \n",
       "37  0.740551  4.921965e-01  1.067308  0.168284  0.447552  0.447368  0.800000   \n",
       "38 -0.267209 -1.092896e-15  0.105890 -0.096162  0.258741  0.342105  0.600000   \n",
       "39 -0.117911  1.230491e-01  0.031935  0.168284  0.286713  0.368421  0.584615   \n",
       "40  3.689184  3.076228e+00  1.067308 -0.228386  1.000000  1.000000  0.800000   \n",
       "41 -0.155236  7.382948e-01 -0.485751 -0.889503  0.279720  0.500000  0.476923   \n",
       "42  0.068711  4.921965e-01 -0.115975 -0.360609  0.321678  0.447368  0.553846   \n",
       "43 -0.080587 -1.092896e-15 -0.115975  0.036061  0.293706  0.342105  0.553846   \n",
       "\n",
       "           3  \n",
       "0   0.447368  \n",
       "1   0.447368  \n",
       "2   0.526316  \n",
       "3   0.000000  \n",
       "4   0.710526  \n",
       "5   0.526316  \n",
       "6   0.368421  \n",
       "7   0.894737  \n",
       "8   1.000000  \n",
       "9   0.394737  \n",
       "10  0.815789  \n",
       "11  0.447368  \n",
       "12  0.578947  \n",
       "13  0.684211  \n",
       "14  0.605263  \n",
       "15  0.421053  \n",
       "16  0.684211  \n",
       "17  0.631579  \n",
       "18  0.447368  \n",
       "19  0.447368  \n",
       "20  0.421053  \n",
       "21  0.684211  \n",
       "22  0.500000  \n",
       "23  0.421053  \n",
       "24  0.447368  \n",
       "25  0.631579  \n",
       "26  0.473684  \n",
       "27  0.447368  \n",
       "28  0.447368  \n",
       "29  0.710526  \n",
       "30  0.315789  \n",
       "31  0.973684  \n",
       "32  0.736842  \n",
       "33  0.657895  \n",
       "34  0.973684  \n",
       "35  0.105263  \n",
       "36  0.394737  \n",
       "37  0.578947  \n",
       "38  0.526316  \n",
       "39  0.578947  \n",
       "40  0.500000  \n",
       "41  0.368421  \n",
       "42  0.473684  \n",
       "43  0.552632  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c9f7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1=pd.concat([pd.DataFrame(x_test1),pd.DataFrame(x_test2)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee4a6545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.155236</td>\n",
       "      <td>0.369147</td>\n",
       "      <td>-0.263886</td>\n",
       "      <td>1.093848</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.416507</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043262</td>\n",
       "      <td>0.369147</td>\n",
       "      <td>-0.411796</td>\n",
       "      <td>1.226071</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.453832</td>\n",
       "      <td>0.246098</td>\n",
       "      <td>-0.485751</td>\n",
       "      <td>1.490518</td>\n",
       "      <td>0.223776</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.192560</td>\n",
       "      <td>-0.123049</td>\n",
       "      <td>-0.485751</td>\n",
       "      <td>1.622742</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.603129</td>\n",
       "      <td>-1.599639</td>\n",
       "      <td>0.697532</td>\n",
       "      <td>-0.360609</td>\n",
       "      <td>0.195804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.218009</td>\n",
       "      <td>0.369147</td>\n",
       "      <td>-0.411796</td>\n",
       "      <td>-2.079513</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.404631</td>\n",
       "      <td>0.123049</td>\n",
       "      <td>1.067308</td>\n",
       "      <td>-0.492833</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.315939</td>\n",
       "      <td>2.337933</td>\n",
       "      <td>1.215219</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.827076</td>\n",
       "      <td>-1.353540</td>\n",
       "      <td>0.475667</td>\n",
       "      <td>-0.228386</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.498916</td>\n",
       "      <td>-1.353540</td>\n",
       "      <td>-2.334632</td>\n",
       "      <td>0.432731</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.106035</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>1.622742</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.461592</td>\n",
       "      <td>-1.107442</td>\n",
       "      <td>-2.260677</td>\n",
       "      <td>0.564954</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.005938</td>\n",
       "      <td>0.246098</td>\n",
       "      <td>-0.042020</td>\n",
       "      <td>-0.757279</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.292658</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>0.432731</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         0         1         2  \\\n",
       "0  -0.155236  0.369147 -0.263886  1.093848  0.279720  0.421053  0.523077   \n",
       "1  -0.416507  0.615246  0.031935 -0.096162  0.230769  0.473684  0.584615   \n",
       "2  -0.043262  0.369147 -0.411796  1.226071  0.300699  0.421053  0.492308   \n",
       "3  -0.453832  0.246098 -0.485751  1.490518  0.223776  0.394737  0.476923   \n",
       "4  -0.192560 -0.123049 -0.485751  1.622742  0.272727  0.315789  0.476923   \n",
       "5  -0.603129 -1.599639  0.697532 -0.360609  0.195804  0.000000  0.723077   \n",
       "6   0.218009  0.369147 -0.411796 -2.079513  0.349650  0.421053  0.492308   \n",
       "7   0.404631  0.123049  1.067308 -0.492833  0.384615  0.368421  0.800000   \n",
       "8   3.315939  2.337933  1.215219 -0.096162  0.930070  0.842105  0.830769   \n",
       "9  -0.827076 -1.353540  0.475667 -0.228386  0.153846  0.052632  0.676923   \n",
       "10 -1.498916 -1.353540 -2.334632  0.432731  0.027972  0.052632  0.092308   \n",
       "11  0.106035  0.615246  0.105890  1.622742  0.328671  0.473684  0.600000   \n",
       "12 -1.461592 -1.107442 -2.260677  0.564954  0.034965  0.105263  0.107692   \n",
       "13 -0.005938  0.246098 -0.042020 -0.757279  0.307692  0.394737  0.569231   \n",
       "14  0.292658  0.615246  0.327756  0.432731  0.363636  0.473684  0.646154   \n",
       "\n",
       "           3  \n",
       "0   0.763158  \n",
       "1   0.526316  \n",
       "2   0.789474  \n",
       "3   0.842105  \n",
       "4   0.868421  \n",
       "5   0.473684  \n",
       "6   0.131579  \n",
       "7   0.447368  \n",
       "8   0.526316  \n",
       "9   0.500000  \n",
       "10  0.631579  \n",
       "11  0.868421  \n",
       "12  0.657895  \n",
       "13  0.394737  \n",
       "14  0.631579  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d84834c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44, 4), (44, 4))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2.shape,x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a4f6e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 4), (15, 4))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test2.shape,x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "15de3dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Fitting I Bayes to the Training set\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "57927440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# classifier = GaussianNB()\n",
    "# classifier.fit(feature, y_train)\n",
    "# GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5209cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Fitting I Bayes to the Training set\n",
    "classifier1 = GaussianNB()\n",
    "classifier1.fit(feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ac6ab45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 1 1 3 1 1 1 4 1 4 2 1 1 4 2 1 4 4 4 2 3 4 4 1 4 4 4 3 1 1 1 1 1 1 4\n",
      " 3 3 3 3 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_train)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dcdd9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 1 1 4 1 4 3 3 2 1 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = classifier1.predict(feature1)\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "19becbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[12  0  0  0]\n",
      " [ 0  3  0  0]\n",
      " [ 7  0  8  1]\n",
      " [ 0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix : \\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "296ee4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[7 0 0 0]\n",
      " [0 1 1 0]\n",
      " [0 0 3 0]\n",
      " [0 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(\"Confusion Matrix : \\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fe3d4f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy : \", accuracy_score(y_train, y_pred))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a6b6353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f1a712df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      1.00      0.77        12\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      0.50      0.67        16\n",
      "           4       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.82        44\n",
      "   macro avg       0.89      0.88      0.85        44\n",
      "weighted avg       0.88      0.82      0.81        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "y_pred=np.around(classifier.predict(x_train))\n",
    "print(metrics.classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "15411889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       0.60      1.00      0.75         3\n",
      "           4       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.79      0.80        15\n",
      "weighted avg       0.92      0.87      0.87        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "y_pred=np.around(classifier.predict(x_test))\n",
    "print(metrics.classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ed37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a638aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy of naive bayes classifier on training set: {:.2f}'\n",
    "#      .format(classifier.score(X_train, y_train)))\n",
    "# print('Accuracy of naive bayes classifier on test set: {:.2f}'\n",
    "#      .format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1be8ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CCL\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(fruits['fruit_name'],label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "302d40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 1 3 1 2 1 1 1 3 4 1 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the test set result  \n",
    "y_pred= classifier.predict(X_test)  \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d9c699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[4 0 1 2]\n",
      " [1 0 0 1]\n",
      " [2 0 0 1]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix : \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a711d71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given data set is:\n",
      "   weather temperature Humidity    wind goes\n",
      "0   Sunny        Warm   Normal  Strong  Yes\n",
      "1   Sunny        Warm   Normal  Strong   No\n",
      "2   Sunny        cold   Normal  Strong  Yes\n",
      "The attributes are:\n",
      " [['Sunny' 'Warm' 'Normal' 'Strong']\n",
      " ['Sunny' 'Warm' 'Normal' 'Strong']\n",
      " ['Sunny' 'cold' 'Normal' 'Strong']]\n",
      "The target is:  ['Yes' 'No' 'Yes']\n",
      "The final hypothesis is: ['Sunny' '?' 'Normal' 'Strong']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "#to read the data in the csv file\n",
    "data = pd.read_csv(\"cs.csv\")\n",
    "print(\"The given data set is:\\n\",data)\n",
    " \n",
    "#making an array of all the attributes\n",
    "d = np.array(data)[:,:-1]\n",
    "print(\"The attributes are:\\n\",d)\n",
    " \n",
    "#segragating the target that has positive and negative examples\n",
    "target = np.array(data)[:,-1]\n",
    "print(\"The target is: \",target)\n",
    " \n",
    "#training function to implement find-s algorithm\n",
    "def train(c,t):\n",
    "    for i, val in enumerate(t):\n",
    "        if val == \"Yes\":\n",
    "            specific_hypothesis = c[i].copy()\n",
    "            break\n",
    "             \n",
    "    for i, val in enumerate(c):\n",
    "        if t[i] == \"Yes\":\n",
    "            for x in range(len(specific_hypothesis)):\n",
    "                if val[x] != specific_hypothesis[x]:\n",
    "                    specific_hypothesis[x] = '?'\n",
    "                else:\n",
    "                    pass\n",
    "                 \n",
    "    return specific_hypothesis\n",
    " \n",
    "#obtaining the final hypothesis\n",
    "print(\"The final hypothesis is:\",train(d,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "050c4618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['weather', 'temperature', 'Humidity', 'wind', 'goes'], ['Sunny', 'Warm', 'Normal', 'Strong', 'Yes'], ['Sunny', 'Warm', 'Normal', 'Strong', 'No'], ['Sunny', 'cold', 'Normal', 'Strong', 'Yes'], ['Sunny', 'warm', 'Normal', 'Strong', 'Yes']]\n",
      "\n",
      "Steps of Candidate Elimination Algorithm 1\n",
      "['Sunny', 'Warm', 'Normal', 'Strong']\n",
      "[['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?']]\n",
      "\n",
      "Steps of Candidate Elimination Algorithm 2\n",
      "['Sunny', 'Warm', 'Normal', 'Strong']\n",
      "[['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?']]\n",
      "\n",
      "Steps of Candidate Elimination Algorithm 3\n",
      "['Sunny', 'Warm', 'Normal', 'Strong']\n",
      "[['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?']]\n",
      "\n",
      "Steps of Candidate Elimination Algorithm 4\n",
      "['Sunny', '?', 'Normal', 'Strong']\n",
      "[['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?']]\n",
      "\n",
      "Steps of Candidate Elimination Algorithm 5\n",
      "['Sunny', '?', 'Normal', 'Strong']\n",
      "[['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?'], ['?', '?', '?', '?']]\n",
      "\n",
      "Final specific hypothesis:\n",
      " ['Sunny', '?', 'Normal', 'Strong']\n",
      "\n",
      "Final general hypothesis:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "with open(\"cs.csv\") as f:\n",
    "    csv_file=csv.reader(f)\n",
    "    data=list(csv_file)\n",
    "    print(data)\n",
    "    s=data[1][:-1]\n",
    "    g=[['?' for i in range(len(s))] for j in range(len(s))]\n",
    "    for i in data:\n",
    "        if i[-1]==\"Yes\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    s[j]='?'\n",
    "                    g[j][j]='?'\n",
    "        elif i[-1]==\"No\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    g[j][j]=s[j]\n",
    "                else:\n",
    "                    g[j][j]=\"?\"\n",
    "        print(\"\\nSteps of Candidate Elimination Algorithm\",data.index(i)+1)\n",
    "        print(s)\n",
    "        print(g)\n",
    "        gh=[]\n",
    "\n",
    "for i in g:\n",
    "    for j in i:\n",
    "        if j!='?':\n",
    "            gh.append(i)\n",
    "            break\n",
    "print(\"\\nFinal specific hypothesis:\\n\",s)\n",
    "print(\"\\nFinal general hypothesis:\\n\",gh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46016982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
